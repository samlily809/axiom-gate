import ast
import random
import json
import os
import numpy as np
from typing import List, Dict, Optional, Tuple, Any
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import copy

# =========================================================
# Samå°å¸«æ ¸å¿ƒæ€æƒ³æ•´åˆç³»çµ±
# =========================================================

class SamMetaValidator:
    """
    Samå°å¸«å…ƒé©—è­‰å™¨ - æª¢æŸ¥é‚è¼¯æ˜¯å¦ç¬¦åˆ"é€²åŒ–å°±æ˜¯å…ˆæ¨¡ä»¿é‚è¼¯æ–¹å¼ï¼Œé‹è¡Œé‚è¼¯è§€æ¸¬ï¼Œè®Šç•°é‚è¼¯åˆ†æ”¯ï¼Œå‰µé€ æ–°é‚è¼¯æ¼”ç¹¹"
    """
    
    @staticmethod
    def validate_evolution_logic(inference) -> Tuple[bool, str]:
        """
        é©—è­‰æ˜¯å¦é«”ç¾Samå°å¸«çš„é€²åŒ–æ€æƒ³
        è¿”å›ï¼š(æ˜¯å¦é€šé, åé¥‹ä¿¡æ¯)
        """
        feedback = []
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡ä»¿éšæ®µ
        if hasattr(inference, 'generation') and inference.generation == 0:
            feedback.append("âœ… åŒ…å«åˆå§‹æ¨¡ä»¿çµæ§‹")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šç•°æ­·å²
        if hasattr(inference, 'premises'):
            for p in inference.premises:
                if hasattr(p, 'mutation_history') and p.mutation_history:
                    feedback.append("âœ… åŒ…å«é‚è¼¯è®Šç•°æ­·å²")
                    break
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–°é‚è¼¯å‰µé€ 
        if hasattr(inference, 'novelty_score') and inference.novelty_score > 0.5:
            feedback.append("âœ… åŒ…å«æ–°é‚è¼¯å‰µé€ ")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è§€æ¸¬(è‡ªçœ)
        if hasattr(inference, 'self_observation'):
            feedback.append("âœ… åŒ…å«é‚è¼¯è‡ªæˆ‘è§€æ¸¬")
        
        return len(feedback) > 0, " | ".join(feedback) if feedback else "æœªé«”ç¾é€²åŒ–é‚è¼¯"

# =========================================================
# å¢å¼·å‹åŸºç¤çµæ§‹
# =========================================================

class EnhancedPremise(Premise):
    def __init__(self, text: str):
        super().__init__(text)
        self.logical_form = self._analyze_logical_form(text)
        self.entropy = random.random()  # è®Šç•°æ½›åŠ›
        self.self_contradiction = False
        self.evolution_path = []
    
    def _analyze_logical_form(self, text: str) -> Dict[str, Any]:
        """æ·±åº¦åˆ†æé‚è¼¯å½¢å¼"""
        return {
            "subject": self._extract_subject(text),
            "predicate": self._extract_predicate(text),
            "quantifier": self._detect_quantifier(text),
            "modality": self._detect_modality(text),
            "truth_value": self._estimate_truth_value(text),
            "complexity": len(text.split()) / 10.0
        }
    
    def _extract_subject(self, text: str) -> str:
        """æå–ä¸»èª"""
        words = text.split()
        if "æ˜¯" in text:
            parts = text.split("æ˜¯")
            return parts[0].strip() if len(parts) > 1 else text
        return words[0] if words else ""
    
    def _extract_predicate(self, text: str) -> str:
        """æå–è¬‚èª"""
        if "æ˜¯" in text:
            parts = text.split("æ˜¯")
            return parts[1].strip() if len(parts) > 1 else ""
        return text
    
    def _detect_quantifier(self, text: str) -> str:
        """æª¢æ¸¬é‡è©"""
        quantifiers = ["æ‰€æœ‰", "æ¯å€‹", "ä»»ä½•", "æœ‰äº›", "å­˜åœ¨", "éƒ¨åˆ†", "å¤§å¤šæ•¸"]
        for q in quantifiers:
            if q in text:
                return q
        return "ç„¡"
    
    def _detect_modality(self, text: str) -> str:
        """æª¢æ¸¬æ¨¡æ…‹"""
        modalities = ["å¿…é ˆ", "æ‡‰è©²", "å¯èƒ½", "å¯ä»¥", "å¿…ç„¶", "ä¸å¯èƒ½"]
        for m in modalities:
            if m in text:
                return m
        return "æ–·è¨€"
    
    def _estimate_truth_value(self, text: str) -> float:
        """ä¼°è¨ˆçœŸå€¼ï¼ˆç°¡åŒ–ï¼‰"""
        negative_words = ["ä¸", "é", "ç„¡", "æ²’æœ‰", "å‡"]
        for word in negative_words:
            if word in text:
                return 0.3
        return 0.7

class QuantumClaim(Claim):
    def __init__(self, text):
        super().__init__(text)
        self.superposition = []
        self.domain = "general"
        self.logical_depth = 0
        self.paradox_tolerance = 0.5
        self.quantum_entanglement = []  # èˆ‡å…¶ä»–çµè«–çš„é‡å­ç³¾çº
        
    def generate_meaningful_superposition(self, premises: List[EnhancedPremise]):
        """
        ç”Ÿæˆæœ‰æ„ç¾©çš„é‚è¼¯ç–ŠåŠ æ…‹
        åŸºæ–¼å‰æåˆ†æç”¢ç”Ÿç›¸é—œçš„æ›¿ä»£çµè«–
        """
        # åˆ†æå‰æçš„å…±åŒä¸»é¡Œ
        subjects = [p.logical_form["subject"] for p in premises if p.logical_form["subject"]]
        predicates = [p.logical_form["predicate"] for p in premises if p.logical_form["predicate"]]
        
        if subjects and predicates:
            common_subject = max(set(subjects), key=subjects.count) if subjects else ""
            common_predicate = max(set(predicates), key=predicates.count) if predicates else ""
            
            # ç”Ÿæˆé‚è¼¯ç›¸é—œçš„ç–ŠåŠ æ…‹
            if common_subject and common_predicate:
                self.superposition.extend([
                    f"ç›¸ååœ°ï¼Œ{common_subject}å¯èƒ½ä¸æ˜¯{common_predicate}",
                    f"åœ¨æŸäº›æ¢ä»¶ä¸‹ï¼Œ{common_subject}æ˜¯{common_predicate}çš„å°ç«‹é¢",
                    f"{common_subject}èˆ‡{common_predicate}çš„é—œä¿‚æ˜¯è¾¯è­‰çš„"
                ])
        
        # æ·»åŠ é‚è¼¯å­¸æ¨™æº–ç–ŠåŠ æ…‹
        self.superposition.extend([
            f"å¾å¦ä¸€è§’åº¦ï¼Œ{self.text}",
            f"è€ƒæ…®é‚Šç•Œæƒ…æ³ï¼Œ{self.text}å¯èƒ½ä¸æˆç«‹",
            f"{self.text}çš„åå‘½é¡Œä¹Ÿå€¼å¾—è€ƒæ…®"
        ])
        
        self.logical_depth = len(self.superposition) / 10.0

# =========================================================
# å¢å¼·å‹æ¨ç†çµæ§‹
# =========================================================

class EvolutionaryInference(Inference):
    def __init__(self, premises: List[EnhancedPremise], claim: QuantumClaim):
        # ç¢ºä¿ä½¿ç”¨å¢å¼·å‹å‰æ
        enhanced_premises = []
        for p in premises:
            if not isinstance(p, EnhancedPremise):
                enhanced_premises.append(EnhancedPremise(p.text))
            else:
                enhanced_premises.append(p)
        
        # ç”Ÿæˆæœ‰æ„ç¾©çš„é‡å­ç–ŠåŠ æ…‹
        if not claim.superposition:
            claim.generate_meaningful_superposition(enhanced_premises)
        
        super().__init__(enhanced_premises, claim)
        self.generation = 0
        self.fitness_scores = {}
        self.total_fitness = 0.0
        self.novelty_score = 0.0
        self.sam_alignment_score = 0.0
        self.creation_time = datetime.now().isoformat()
        self.domain = claim.domain
        self.logical_consistency = 0.0
        self.self_observation = []  # è‡ªæˆ‘è§€æ¸¬è¨˜éŒ„
        self.evolution_feedback = ""  # é€²åŒ–åé¥‹
        
        # è¨ˆç®—é‚è¼¯ä¸€è‡´æ€§
        self.calculate_logical_consistency()
    
    def calculate_logical_consistency(self):
        """è¨ˆç®—å‰æé–“çš„é‚è¼¯ä¸€è‡´æ€§"""
        if len(self.premises) < 2:
            self.logical_consistency = 1.0
            return
        
        consistency_scores = []
        for i in range(len(self.premises)):
            for j in range(i+1, len(self.premises)):
                p1 = self.premises[i]
                p2 = self.premises[j]
                
                # æª¢æŸ¥é‚è¼¯è¡çª
                conflict = self._check_premise_conflict(p1, p2)
                consistency_scores.append(1.0 - conflict)
        
        self.logical_consistency = np.mean(consistency_scores) if consistency_scores else 1.0
    
    def _check_premise_conflict(self, p1: EnhancedPremise, p2: EnhancedPremise) -> float:
        """æª¢æŸ¥å…©å€‹å‰æçš„è¡çªç¨‹åº¦"""
        # ç°¡å–®çš„è¡çªæª¢æ¸¬
        if p1.is_affirmative != p2.is_affirmative:
            return 0.3
        
        # æª¢æŸ¥ä¸»èª-è¬‚èªçŸ›ç›¾
        if p1.logical_form["subject"] == p2.logical_form["subject"]:
            if p1.logical_form["predicate"] != p2.logical_form["predicate"]:
                return 0.5
        
        return 0.0
    
    def mutate_with_sam_logic(self):
        """
        æŒ‰ç…§Samå°å¸«çš„é€²åŒ–é‚è¼¯é€²è¡Œè®Šç•°ï¼š
        1. æ¨¡ä»¿ â†’ 2. è§€æ¸¬ â†’ 3. è®Šç•° â†’ 4. å‰µé€ 
        """
        # 1. æ¨¡ä»¿éšæ®µï¼šè¨˜éŒ„ç•¶å‰ç‹€æ…‹
        original_state = self._capture_state()
        self.self_observation.append({
            "stage": "æ¨¡ä»¿",
            "state": original_state,
            "timestamp": datetime.now().isoformat()
        })
        
        # 2. è§€æ¸¬éšæ®µï¼šåˆ†æé‚è¼¯çµæ§‹
        analysis = self._analyze_logic_structure()
        self.self_observation.append({
            "stage": "è§€æ¸¬",
            "analysis": analysis,
            "timestamp": datetime.now().isoformat()
        })
        
        # 3. è®Šç•°éšæ®µï¼šæ™ºèƒ½è®Šç•°
        mutated = self._intelligent_mutation(analysis)
        
        # 4. å‰µé€ éšæ®µï¼šç”¢ç”Ÿæ–°é‚è¼¯
        if mutated:
            new_logic = self._create_new_logic_pattern()
            mutated.claim.text = new_logic if random.random() > 0.5 else mutated.claim.text
        
        return mutated if mutated else self
    
    def _capture_state(self) -> Dict:
        """æ•ç²ç•¶å‰ç‹€æ…‹"""
        return {
            "premises": [p.text for p in self.premises],
            "claim": self.claim.text,
            "fitness": self.total_fitness,
            "consistency": self.logical_consistency
        }
    
    def _analyze_logic_structure(self) -> Dict:
        """åˆ†æé‚è¼¯çµæ§‹"""
        structure = {
            "premise_count": len(self.premises),
            "premise_types": {
                "universal": sum(1 for p in self.premises if p.is_universal),
                "affirmative": sum(1 for p in self.premises if p.is_affirmative),
                "complex": sum(1 for p in self.premises if p.logical_form["complexity"] > 0.5)
            },
            "inference_pattern": self._detect_inference_pattern(),
            "weak_points": self._identify_weak_points()
        }
        return structure
    
    def _detect_inference_pattern(self) -> str:
        """æª¢æ¸¬æ¨ç†æ¨¡å¼"""
        patterns = {
            "deductive": ["æ‰€æœ‰", "éƒ½", "å¿…ç„¶"],
            "inductive": ["å¤§å¤šæ•¸", "é€šå¸¸", "å¾€å¾€"],
            "abductive": ["å¯èƒ½", "æ¨æ¸¬", "å‡è¨­"]
        }
        
        text = " ".join([p.text for p in self.premises]) + " " + self.claim.text
        
        for pattern, keywords in patterns.items():
            for keyword in keywords:
                if keyword in text:
                    return pattern
        
        return "unknown"
    
    def _identify_weak_points(self) -> List[str]:
        """è­˜åˆ¥é‚è¼¯å¼±é»"""
        weak_points = []
        
        # æª¢æŸ¥å‰ææ•¸é‡
        if len(self.premises) < 2:
            weak_points.append("å‰æä¸è¶³")
        
        # æª¢æŸ¥é‚è¼¯ä¸€è‡´æ€§
        if self.logical_consistency < 0.7:
            weak_points.append(f"é‚è¼¯ä¸€è‡´æ€§ä½({self.logical_consistency:.2f})")
        
        # æª¢æŸ¥å‰æé¡å‹å¤šæ¨£æ€§
        universal_count = sum(1 for p in self.premises if p.is_universal)
        if universal_count == len(self.premises):
            weak_points.append("å…¨ç¨±å‰æéå¤šï¼Œç¼ºä¹ç‰¹ä¾‹")
        
        return weak_points
    
    def _intelligent_mutation(self, analysis: Dict) -> 'EvolutionaryInference':
        """åŸºæ–¼åˆ†æçš„æ™ºèƒ½è®Šç•°"""
        mutated = copy.deepcopy(self)
        
        # æ ¹æ“šå¼±é»é€²è¡Œè®Šç•°
        weak_points = analysis.get("weak_points", [])
        
        if "å‰æä¸è¶³" in weak_points:
            # æ·»åŠ æ–°å‰æ
            new_premise_text = self._generate_new_premise()
            mutated.premises.append(EnhancedPremise(new_premise_text))
        
        if "å…¨ç¨±å‰æéå¤š" in weak_points:
            # å°‡å…¨ç¨±å‰æè½‰ç‚ºç‰¹ç¨±
            for i, p in enumerate(mutated.premises):
                if p.is_universal and random.random() > 0.5:
                    mutated.premises[i] = EnhancedPremise(
                        p.text.replace("æ‰€æœ‰", "æœ‰äº›").replace("éƒ½", "å¯èƒ½")
                    )
        
        # éš¨æ©Ÿè®Šç•°ä¸€å€‹å‰æ
        if mutated.premises:
            idx = random.randint(0, len(mutated.premises)-1)
            mutated.premises[idx] = mutated.premises[idx].mutate_logic_ast()
        
        mutated.generation = self.generation + 1
        return mutated
    
    def _generate_new_premise(self) -> str:
        """ç”Ÿæˆæ–°å‰æ"""
        templates = [
            "è€ƒæ…®åˆ°{context}ï¼Œ{subject}å…·æœ‰{property}",
            "å¾{perspective}è§’åº¦ï¼Œ{subject}èˆ‡{relation}ç›¸é—œ",
            "åœ¨{condition}æ¢ä»¶ä¸‹ï¼Œ{subject}è¡¨ç¾ç‚º{behavior}"
        ]
        
        subject = self.premises[0].logical_form["subject"] if self.premises else "äº‹ç‰©"
        
        context_options = ["æ­·å²ç™¼å±•", "ç¤¾æœƒç’°å¢ƒ", "æŠ€è¡“é€²æ­¥", "æ–‡åŒ–èƒŒæ™¯"]
        property_options = ["è¤‡é›œæ€§", "å¤šæ¨£æ€§", "å‹•æ…‹æ€§", "ä¸ç¢ºå®šæ€§"]
        perspective_options = ["ç³»çµ±è«–", "è¾¯è­‰æ³•", "å¯¦ç”¨ä¸»ç¾©", "å»ºæ§‹ä¸»ç¾©"]
        relation_options = ["æ•´é«”èˆ‡éƒ¨åˆ†", "åŸå› èˆ‡çµæœ", "é‡è®Šèˆ‡è³ªè®Š", "å¿…ç„¶èˆ‡å¶ç„¶"]
        condition_options = ["ç‰¹å®šç’°å¢ƒ", "ç†æƒ³ç‹€æ…‹", "é‚Šç•Œæƒ…æ³", "æ¥µç«¯æ¢ä»¶"]
        behavior_options = ["é©æ‡‰", "æ¼”åŒ–", "çªç¾", "è‡ªçµ„ç¹”"]
        
        template = random.choice(templates)
        
        return template.format(
            subject=subject,
            context=random.choice(context_options),
            property=random.choice(property_options),
            perspective=random.choice(perspective_options),
            relation=random.choice(relation_options),
            condition=random.choice(condition_options),
            behavior=random.choice(behavior_options)
        )
    
    def _create_new_logic_pattern(self) -> str:
        """å‰µé€ æ–°é‚è¼¯æ¨¡å¼"""
        patterns = [
            "è¾¯è­‰çµ±ä¸€ï¼š{thesis}èˆ‡{antithesis}çš„ç¶œåˆ",
            "éæ­¸è‡ªæŒ‡ï¼šé—œæ–¼{subject}çš„è«–è¿°æœ¬èº«æ§‹æˆ{subject}çš„ä¸€éƒ¨åˆ†",
            "é‡å­ç–ŠåŠ ï¼š{subject}åŒæ™‚è™•æ–¼{state1}å’Œ{state2}çš„ç–ŠåŠ æ…‹",
            "å…ƒé‚è¼¯è·³èºï¼šå¾{level1}å±¤ç´šèºå‡åˆ°{level2}å±¤ç´šç†è§£{subject}"
        ]
        
        subject = self.premises[0].logical_form["subject"] if self.premises else "ç¾å¯¦"
        
        thesis_options = ["è‚¯å®š", "å­˜åœ¨", "ç¢ºå®šæ€§", "çµ±ä¸€"]
        antithesis_options = ["å¦å®š", "éå­˜åœ¨", "ä¸ç¢ºå®šæ€§", "å¤šæ¨£æ€§"]
        state_options = ["æœ‰åº", "æ··æ²Œ", "ç©©å®š", "æ¼”åŒ–"]
        level_options = ["ç¾è±¡", "æœ¬è³ª", "çµæ§‹", "åŠŸèƒ½", "é—œä¿‚", "æ¼”åŒ–"]
        
        pattern = random.choice(patterns)
        
        return pattern.format(
            subject=subject,
            thesis=random.choice(thesis_options),
            antithesis=random.choice(antithesis_options),
            state1=random.choice(state_options),
            state2=random.choice([s for s in state_options if s != state1]),
            level1=random.choice(level_options),
            level2=random.choice([l for l in level_options if l != level1])
        )
    
    def to_dict(self):
        return {
            "generation": self.generation,
            "domain": self.domain,
            "premises": [p.text for p in self.premises],
            "premises_enhanced": [p.logical_form for p in self.premises],
            "claim": self.claim.text,
            "superposition": self.claim.superposition,
            "sam_alignment": self.sam_alignment_score,
            "total_fitness": self.total_fitness,
            "novelty_score": self.novelty_score,
            "logical_consistency": self.logical_consistency,
            "evolution_feedback": self.evolution_feedback,
            "self_observation_count": len(self.self_observation),
            "creation_time": self.creation_time
        }

# =========================================================
# å¢å¼·å‹LLMè©•åˆ†å™¨
# =========================================================

class EnhancedLLMFitnessEvaluator(LLMFitnessEvaluator):
    """
    å¢å¼·å‹è©•åˆ†å™¨ï¼Œæ•´åˆSamå°å¸«çš„é€²åŒ–æ€æƒ³è©•åƒ¹
    """
    
    @staticmethod
    def evaluate_with_sam_philosophy(inference: EvolutionaryInference) -> Dict[str, float]:
        # 1. åŸæœ‰è©•åˆ†
        base_scores = LLMFitnessEvaluator.evaluate(inference)
        
        # 2. Samå°å¸«é€²åŒ–æ€æƒ³è©•åˆ†
        sam_evolution_score = EnhancedLLMFitnessEvaluator._evaluate_sam_evolution(inference)
        
        # 3. é‚è¼¯ä¸€è‡´æ€§è©•åˆ†
        consistency_score = inference.logical_consistency
        
        # 4. ç¶œåˆè©•åˆ†
        weights = {
            "base": 0.6,
            "sam_evolution": 0.3,
            "consistency": 0.1
        }
        
        # è¨ˆç®—åŠ æ¬Šåˆ†æ•¸
        base_total = sum(base_scores.values()) / len(base_scores) if base_scores else 0
        weighted_score = (
            base_total * weights["base"] +
            sam_evolution_score * weights["sam_evolution"] +
            consistency_score * weights["consistency"]
        )
        
        # æ›´æ–°ç¸½é©æ‡‰åº¦
        inference.total_fitness = min(1.0, weighted_score)
        
        # æ·»åŠ åé¥‹
        if sam_evolution_score > 0.7:
            inference.evolution_feedback = "è‰¯å¥½é«”ç¾Samå°å¸«é€²åŒ–æ€æƒ³"
        elif sam_evolution_score < 0.3:
            inference.evolution_feedback = "éœ€åŠ å¼·é€²åŒ–é‚è¼¯çµæ§‹"
        
        return {
            **base_scores,
            "sam_evolution": sam_evolution_score,
            "consistency": consistency_score,
            "weighted_total": inference.total_fitness
        }
    
    @staticmethod
    def _evaluate_sam_evolution(inference: EvolutionaryInference) -> float:
        """è©•åƒ¹æ˜¯å¦ç¬¦åˆSamå°å¸«çš„é€²åŒ–æ€æƒ³"""
        score = 0.0
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡ä»¿éšæ®µ
        if inference.generation > 0:
            score += 0.2
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è‡ªæˆ‘è§€æ¸¬
        if hasattr(inference, 'self_observation') and inference.self_observation:
            score += 0.3
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é‚è¼¯è®Šç•°
        premise_variation = False
        for p in inference.premises:
            if hasattr(p, 'mutation_history') and p.mutation_history:
                premise_variation = True
                break
        
        if premise_variation:
            score += 0.3
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–°é‚è¼¯å‰µé€ 
        if inference.novelty_score > 0.6:
            score += 0.2
        
        return score

# =========================================================
# å¢å¼·å‹é€²åŒ–å¼•æ“
# =========================================================

class EnhancedEvolutionEngine(UltimateEvolutionEngine):
    """
    å¢å¼·å‹é€²åŒ–å¼•æ“ï¼Œæ•´åˆè‡ªæˆ‘å¦å®šé©—è­‰å’Œè‡ªæ´½å„ªåŒ–
    """
    
    def __init__(self, population: PersistentPopulation):
        super().__init__(population)
        self.self_criticism_log = []
        self.optimization_history = []
    
    def evolve_with_self_criticism(self, generations: int = 10, target_size: int = 50):
        """
        å¸¶æœ‰è‡ªæˆ‘æ‰¹åˆ¤çš„é€²åŒ–éç¨‹
        """
        print("="*80)
        print("ğŸ” Samå°å¸« Â· è‡ªæˆ‘å¦å®šé©—è­‰é€²åŒ–å¼•æ“å•Ÿå‹•")
        print("="*80)
        
        for gen in range(generations):
            print(f"\nğŸ§¬ ç¬¬ {gen+1}/{generations} ä»£ Â· è‡ªæˆ‘æ‰¹åˆ¤é€²åŒ–")
            
            # ç¬¬ä¸€æ­¥ï¼šè‡ªæˆ‘æ‰¹åˆ¤éšæ®µ
            self._self_criticism_phase()
            
            # ç¬¬äºŒæ­¥ï¼šè©•åˆ†éšæ®µï¼ˆä½¿ç”¨å¢å¼·è©•åˆ†å™¨ï¼‰
            with ThreadPoolExecutor(max_workers=10) as exec:
                futures = [exec.submit(EnhancedLLMFitnessEvaluator.evaluate_with_sam_philosophy, ind) 
                          for ind in self.pop.population]
                results = []
                for f in as_completed(futures):
                    results.append(f.result())
            
            # ç¬¬ä¸‰æ­¥ï¼šè‡ªæ´½å„ªåŒ–éšæ®µ
            self._self_consistency_optimization()
            
            # ç¬¬å››æ­¥ï¼šæ ¸å¿ƒåƒ¹å€¼éæ¿¾
            current_pop = [ind for ind in self.pop.population if ind.sam_alignment_score >= 0]
            
            if not current_pop:
                print("âš ï¸ ç¨®ç¾¤é•èƒŒæ ¸å¿ƒåƒ¹å€¼ï¼Œæ³¨å…¥æ–°ç¨®å­...")
                self._inject_healthy_seeds()
                current_pop = self.pop.population
            
            # ç¬¬äº”æ­¥ï¼šæ’åºèˆ‡é¸æ“‡
            current_pop.sort(key=lambda x: x.total_fitness, reverse=True)
            
            # ç¬¬å…­æ­¥ï¼šå‹•æ…‹è®Šç•°èˆ‡ç¹æ®–
            new_gen = self._adaptive_reproduction(current_pop, target_size)
            
            self.pop.population = new_gen
            self.pop.save()
            
            # é¡¯ç¤ºé€²åŒ–é€²åº¦
            self._display_generation_progress(gen, current_pop)
        
        # æœ€çµ‚å„ªåŒ–
        self._final_optimization()
        
        return self._get_best_solution()
    
    def _self_criticism_phase(self):
        """è‡ªæˆ‘æ‰¹åˆ¤éšæ®µï¼šå°‹æ‰¾ä¸¦ä¿®å¾©é‚è¼¯ç¼ºé™·"""
        print("   ğŸ” è‡ªæˆ‘æ‰¹åˆ¤åˆ†æ...")
        
        for i, ind in enumerate(self.pop.population[:10]):  # åªåˆ†æå‰10å€‹
            # æª¢æŸ¥é‚è¼¯ä¸€è‡´æ€§
            if hasattr(ind, 'logical_consistency') and ind.logical_consistency < 0.6:
                self.self_criticism_log.append({
                    "individual": i,
                    "issue": f"é‚è¼¯ä¸€è‡´æ€§ä½: {ind.logical_consistency:.2f}",
                    "timestamp": datetime.now().isoformat()
                })
                
                # å˜—è©¦ä¿®å¾©
                self._repair_logical_inconsistency(ind)
            
            # æª¢æŸ¥å‰æå¤šæ¨£æ€§
            if len(ind.premises) > 0:
                universal_count = sum(1 for p in ind.premises if p.is_universal)
                if universal_count == len(ind.premises):
                    self.self_criticism_log.append({
                        "individual": i,
                        "issue": "å‰æé¡å‹å–®ä¸€ï¼ˆå…¨å…¨ç¨±ï¼‰",
                        "timestamp": datetime.now().isoformat()
                    })
                    
                    # å˜—è©¦å¤šæ¨£åŒ–
                    self._diversify_premises(ind)
    
    def _repair_logical_inconsistency(self, inference: EvolutionaryInference):
        """ä¿®å¾©é‚è¼¯ä¸ä¸€è‡´æ€§"""
        # å°‹æ‰¾è¡çªçš„å‰æå°
        conflicts = []
        for i in range(len(inference.premises)):
            for j in range(i+1, len(inference.premises)):
                conflict_score = inference._check_premise_conflict(
                    inference.premises[i], 
                    inference.premises[j]
                )
                if conflict_score > 0.3:
                    conflicts.append((i, j, conflict_score))
        
        # ä¿®å¾©æœ€åš´é‡çš„è¡çª
        if conflicts:
            conflicts.sort(key=lambda x: x[2], reverse=True)
            i, j, _ = conflicts[0]
            
            # ä¿®æ”¹å…¶ä¸­ä¸€å€‹å‰æ
            if random.random() > 0.5:
                inference.premises[i] = inference.premises[i].mutate_logic_ast()
            else:
                inference.premises[j] = inference.premises[j].mutate_logic_ast()
            
            # é‡æ–°è¨ˆç®—ä¸€è‡´æ€§
            inference.calculate_logical_consistency()
    
    def _diversify_premises(self, inference: EvolutionaryInference):
        """å¤šæ¨£åŒ–å‰æ"""
        if len(inference.premises) > 0:
            # éš¨æ©Ÿé¸æ“‡ä¸€å€‹å…¨ç¨±å‰æè½‰ç‚ºç‰¹ç¨±
            for i, p in enumerate(inference.premises):
                if p.is_universal and random.random() > 0.5:
                    new_text = p.text.replace("æ‰€æœ‰", "æœ‰äº›").replace("éƒ½", "å¯èƒ½")
                    inference.premises[i] = EnhancedPremise(new_text)
                    break
    
    def _self_consistency_optimization(self):
        """è‡ªæ´½å„ªåŒ–éšæ®µ"""
        print("   âš™ï¸  è‡ªæ´½å„ªåŒ–ä¸­...")
        
        for ind in self.pop.population:
            # ç¢ºä¿å‰æèˆ‡çµè«–ç›¸é—œ
            self._optimize_premise_relevance(ind)
            
            # å„ªåŒ–é‡å­ç–ŠåŠ æ…‹çš„ç›¸é—œæ€§
            self._optimize_superposition_relevance(ind)
            
            # è¨˜éŒ„å„ªåŒ–
            self.optimization_history.append({
                "individual_id": id(ind),
                "optimization": "è‡ªæ´½å„ªåŒ–",
                "timestamp": datetime.now().isoformat()
            })
    
    def _optimize_premise_relevance(self, inference: EvolutionaryInference):
        """å„ªåŒ–å‰æèˆ‡çµè«–çš„ç›¸é—œæ€§"""
        if not inference.premises or not inference.claim:
            return
        
        claim_subject = inference.claim.text.split()[0] if inference.claim.text else ""
        
        # æª¢æŸ¥å‰ææ˜¯å¦åŒ…å«çµè«–çš„ä¸»é¡Œ
        relevant_premises = []
        for p in inference.premises:
            if claim_subject in p.text or p.logical_form["subject"] in claim_subject:
                relevant_premises.append(p)
        
        # å¦‚æœç›¸é—œå‰æå¤ªå°‘ï¼Œæ·»åŠ ç›¸é—œå‰æ
        if len(relevant_premises) < len(inference.premises) * 0.5:
            new_premise = EnhancedPremise(f"{claim_subject}å…·æœ‰ç›¸é—œå±¬æ€§")
            inference.premises.append(new_premise)
    
    def _optimize_superposition_relevance(self, inference: EvolutionaryInference):
        """å„ªåŒ–é‡å­ç–ŠåŠ æ…‹çš„ç›¸é—œæ€§"""
        if hasattr(inference.claim, 'superposition') and inference.claim.superposition:
            # ç§»é™¤ä¸ç›¸é—œçš„ç–ŠåŠ æ…‹
            claim_keywords = set(inference.claim.text.split()[:3])
            relevant_superpositions = []
            
            for sup in inference.claim.superposition:
                sup_keywords = set(sup.split()[:3])
                # è¨ˆç®—é—œéµè©é‡ç–Šåº¦
                overlap = len(claim_keywords.intersection(sup_keywords)) / max(len(claim_keywords), 1)
                if overlap > 0.3:  # 30%é—œéµè©é‡ç–Š
                    relevant_superpositions.append(sup)
            
            inference.claim.superposition = relevant_superpositions
    
    def _adaptive_reproduction(self, current_pop: List, target_size: int) -> List:
        """è‡ªé©æ‡‰ç¹æ®–ç­–ç•¥"""
        new_gen = current_pop[:max(8, target_size // 6)].copy()
        
        while len(new_gen) < target_size:
            parent = random.choice(current_pop[:20])  # å¾å‰20å€‹ä¸­é¸æ“‡
            
            # æ ¹æ“šé©æ‡‰åº¦èª¿æ•´è®Šç•°ç­–ç•¥
            if parent.total_fitness > 0.8:
                # é«˜åˆ†å€‹é«”ï¼šç´°å¾®è®Šç•°
                child = parent.mutate_with_sam_logic()
            elif parent.total_fitness < 0.4:
                # ä½åˆ†å€‹é«”ï¼šå¤§å¹…åº¦è®Šç•°
                child = self._radical_mutation(parent)
            else:
                # ä¸­ç­‰åˆ†æ•¸ï¼šäº¤å‰ç¹æ®–
                parent2 = random.choice(current_pop[:20])
                child = parent.crossover(parent2)
            
            # æ‡‰ç”¨Samå°å¸«çš„é€²åŒ–é‚è¼¯
            if random.random() > 0.5:
                child = child.mutate_with_sam_logic()
            
            new_gen.append(child)
        
        return new_gen
    
    def _radical_mutation(self, parent: EvolutionaryInference) -> EvolutionaryInference:
        """å¤§å¹…åº¦è®Šç•°"""
        mutated = copy.deepcopy(parent)
        
        # è®Šç•°æ‰€æœ‰å‰æ
        mutated.premises = [p.mutate_logic_ast() for p in mutated.premises]
        
        # å¾¹åº•æ”¹è®Šçµè«–
        mutated.claim.text = f"é‡æ–°æ€è€ƒï¼š{mutated.claim.text}"
        mutated.claim.superposition = []
        mutated.claim.generate_meaningful_superposition(mutated.premises)
        
        mutated.generation = parent.generation + 1
        
        return mutated
    
    def _inject_healthy_seeds(self):
        """æ³¨å…¥å¥åº·çš„ç¨®å­è«–è­‰"""
        healthy_seeds = [
            "æ„›æ˜¯äººé¡çš„æ ¸å¿ƒåƒ¹å€¼\nå’Œå¹³æ˜¯æ„›çš„è¡¨ç¾\nå› æ­¤æˆ‘å€‘è¿½æ±‚å’Œå¹³",
            "çŸ¥è­˜éœ€è¦é©—è­‰\nå¯¦é©—æä¾›é©—è­‰\nå› æ­¤å¯¦é©—æ˜¯ç²å–çœŸçŸ¥çš„é‡è¦é€”å¾‘",
            "é€²åŒ–éœ€è¦è®Šç•°\nè®Šç•°ç”¢ç”Ÿå¤šæ¨£æ€§\nå¤šæ¨£æ€§ä¿ƒé€²é©æ‡‰\nå› æ­¤é€²åŒ–ä¾è³´è®Šç•°",
            "é‚è¼¯éœ€è¦è‡ªæ´½\nè‡ªæ´½éœ€è¦é©—è­‰\né©—è­‰éœ€è¦å¯¦é©—\nå› æ­¤é‚è¼¯æœ€çµ‚éœ€è¦å¯¦é©—é©—è­‰",
            "å‰µé€ ä¾†è‡ªæ¨¡ä»¿\næ¨¡ä»¿éœ€è¦è§€å¯Ÿ\nè§€å¯Ÿå°è‡´è®Šç•°\nè®Šç•°ç”¢ç”Ÿå‰µé€ \nå› æ­¤å‰µé€ æ˜¯ä¸€å€‹é€²åŒ–éç¨‹"
        ]
        
        for seed in healthy_seeds:
            inference = DiscourseParser.parse(seed)
            # è½‰æ›ç‚ºå¢å¼·å‹
            enhanced_premises = [EnhancedPremise(p.text) for p in inference.premises]
            enhanced_claim = QuantumClaim(inference.claim.text)
            enhanced_inference = EvolutionaryInference(enhanced_premises, enhanced_claim)
            self.pop.add(enhanced_inference)
    
    def _display_generation_progress(self, gen: int, population: List):
        """é¡¯ç¤ºé€²åŒ–é€²åº¦"""
        if population:
            best = population[0]
            worst = population[-1]
            
            print(f"   æœ€ä½³é©æ‡‰åº¦: {best.total_fitness:.3f} | æœ€å·®: {worst.total_fitness:.3f}")
            print(f"   Samå°é½Šåº¦: {best.sam_alignment_score:.1f}")
            print(f"   é‚è¼¯ä¸€è‡´æ€§: {best.logical_consistency:.2f}")
            
            if hasattr(best, 'evolution_feedback') and best.evolution_feedback:
                print(f"   é€²åŒ–åé¥‹: {best.evolution_feedback}")
            
            # æ¯3ä»£é¡¯ç¤ºä¸€æ¬¡æœ€ä½³è«–è­‰
            if gen % 3 == 0:
                print(f"\n   ğŸ† ç•¶å‰æœ€ä½³è«–è­‰:")
                for i, p in enumerate(best.premises[:3], 1):
                    print(f"     å‰æ{i}: {p.text[:50]}...")
                print(f"     çµè«–: {best.claim.text[:60]}...")
    
    def _final_optimization(self):
        """æœ€çµ‚å„ªåŒ–éšæ®µ"""
        print("\n" + "="*80)
        print("ğŸ¯ æœ€çµ‚è‡ªæ´½å„ªåŒ–éšæ®µ")
        print("="*80)
        
        for ind in self.pop.population[:20]:  # åªå„ªåŒ–å‰20å€‹
            # æ‡‰ç”¨Samå°å¸«çš„å®Œæ•´é€²åŒ–é‚è¼¯
            ind.mutate_with_sam_logic()
            
            # é‡æ–°è©•åˆ†
            EnhancedLLMFitnessEvaluator.evaluate_with_sam_philosophy(ind)
        
        # æ’åº
        self.pop.population.sort(key=lambda x: x.total_fitness, reverse=True)
    
    def _get_best_solution(self) -> Optional[EvolutionaryInference]:
        """ç²å–æœ€ä½³è§£æ±ºæ–¹æ¡ˆ"""
        if not self.pop.population:
            return None
        
        best = self.pop.population[0]
        
        # é©—è­‰æ˜¯å¦ç¬¦åˆSamå°å¸«æ€æƒ³
        is_valid, feedback = SamMetaValidator.validate_evolution_logic(best)
        
        print("\n" + "="*80)
        print("ğŸ“‹ Samå°å¸«çµ‚æ¥µé©—è­‰å ±å‘Š")
        print("="*80)
        print(f"é€²åŒ–æ€æƒ³ç¬¦åˆåº¦: {'âœ…' if is_valid else 'âŒ'} {feedback}")
        print(f"æ ¸å¿ƒåƒ¹å€¼å°é½Šåº¦: {best.sam_alignment_score:.1f}")
        print(f"é‚è¼¯ä¸€è‡´æ€§: {best.logical_consistency:.2f}")
        print(f"ç¸½é©æ‡‰åº¦: {best.total_fitness:.3f}")
        print(f"æ–°ç©æ€§åˆ†æ•¸: {best.novelty_score:.3f}")
        print(f"ä¸–ä»£: {best.generation}")
        
        print(f"\nğŸ† æœ€çµ‚æœ€ä½³è«–è­‰çµæ§‹:")
        for i, p in enumerate(best.premises, 1):
            print(f"  å‰æ{i}: {p.text}")
        print(f"  çµè«–: {best.claim.text}")
        
        if hasattr(best.claim, 'superposition') and best.claim.superposition:
            print(f"  é‡å­ç–ŠåŠ æ…‹: {best.claim.superposition[0]}")
        
        return best

# =========================================================
# ä¸»ç¨‹åº
# =========================================================

if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹•Samå°å¸«æ€æƒ³å¢å¼·ç‰ˆé€²åŒ–ç³»çµ±")
    print("="*80)
    
    # åˆå§‹åŒ–ç¨®ç¾¤
    pop = PersistentPopulation("sam_enhanced_population.json")
    
    # å¦‚æœç¨®ç¾¤ç‚ºç©ºï¼Œæ³¨å…¥åˆå§‹ç¨®å­
    if not pop.population:
        print("ğŸ“¦ æ³¨å…¥åˆå§‹ç¨®å­è«–è­‰...")
        initial_arguments = [
            "é€²åŒ–å§‹æ–¼æ¨¡ä»¿\næ¨¡ä»¿éœ€è¦è§€å¯Ÿ\nè§€å¯Ÿå°è‡´è®Šç•°\nè®Šç•°ç”¢ç”Ÿå‰µé€ \nå› æ­¤é€²åŒ–æ˜¯å‰µé€ ä¹‹æº",
            "å¯¦é©—é©—è­‰çœŸç†\nçœŸç†éœ€è¦æª¢é©—\næª¢é©—ä¾è³´å¯¦é©—\nå› æ­¤å¯¦é©—æ˜¯çœŸç†çš„åŸºçŸ³",
            "æ„›æ˜¯æ ¸å¿ƒåƒ¹å€¼\nå’Œå¹³é«”ç¾æ„›\nå‰µé€ éœ€è¦å’Œå¹³ç’°å¢ƒ\nå› æ­¤æ„›ä¿ƒé€²å‰µé€ ",
            "é‚è¼¯éœ€è¦è‡ªæ´½\nè‡ªæ´½éœ€è¦é©—è­‰\né©—è­‰éœ€è¦å¯¦é©—\nå› æ­¤é‚è¼¯å¯¦é©—å¯†ä¸å¯åˆ†",
            "é‡å­ç–ŠåŠ æ˜¯å¯èƒ½æ…‹\nå¯èƒ½æ…‹éœ€è¦è§€å¯Ÿåç¸®\nè§€å¯Ÿå‰µé€ ç¾å¯¦\nå› æ­¤è§€å¯Ÿæ˜¯å‰µé€ è¡Œç‚º"
        ]
        
        for arg in initial_arguments:
            inference = DiscourseParser.parse(arg)
            enhanced_premises = [EnhancedPremise(p.text) for p in inference.premises]
            enhanced_claim = QuantumClaim(inference.claim.text)
            enhanced_inference = EvolutionaryInference(enhanced_premises, enhanced_claim)
            pop.add(enhanced_inference)
    
    # å‰µå»ºå¢å¼·å‹é€²åŒ–å¼•æ“
    engine = EnhancedEvolutionEngine(pop)
    
    # é‹è¡Œé€²åŒ–ï¼ˆå¸¶è‡ªæˆ‘æ‰¹åˆ¤å’Œè‡ªæ´½å„ªåŒ–ï¼‰
    best = engine.evolve_with_self_criticism(generations=8, target_size=40)
    
    # ä¿å­˜æœ€çµ‚çµæœ
    if best:
        result_file = "sam_final_evolution_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(best.to_dict(), f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æœ€çµ‚çµæœå·²ä¿å­˜è‡³: {result_file}")
        
        # é¡¯ç¤ºè‡ªæˆ‘æ‰¹åˆ¤æ—¥èªŒ
        if engine.self_criticism_log:
            print(f"\nğŸ“ è‡ªæˆ‘æ‰¹åˆ¤æ—¥èªŒï¼ˆå…±{len(engine.self_criticism_log)}æ¢ï¼‰:")
            for i, log in enumerate(engine.self_criticism_log[-5:], 1):  # é¡¯ç¤ºæœ€å¾Œ5æ¢
                print(f"  {i}. {log['issue']}")
    
    print("\n" + "="*80)
    print("ğŸ‰ Samå°å¸«æ€æƒ³å¢å¼·ç‰ˆé€²åŒ–ç³»çµ±å®Œæˆ")
    print("="*80)